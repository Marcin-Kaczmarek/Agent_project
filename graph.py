import os
from typing import TypedDict, List
from dotenv import load_dotenv

# LangGraph & LangChain imports
from langgraph.graph import StateGraph, END
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import SystemMessage, HumanMessage

# Import our custom tool
from tools import web_search

# Load environment variables
load_dotenv()

# --- 1. SETUP GEMINI ---
# We use Gemini 1.5 Pro for its large context window (ideal for reading search results)
llm = ChatGoogleGenerativeAI(
    model="gemini-1.5-pro",
    temperature=0.2,
    convert_system_message_to_human=True
)

# --- 2. DEFINE STATE ---
class AgentState(TypedDict):
    task: str                 # The user's initial request
    search_queries: List[str] # Queries generated by the researcher
    research_data: str        # Raw text gathered from the web
    analysis: str             # Intermediate analysis
    final_report: str         # Final formatted output

# --- 3. DEFINE AGENT NODES ---

def researcher_node(state: AgentState):
    """
    Agent 1: Break down the task into search queries and gather data.
    """
    print("--- üïµÔ∏è‚Äç‚ôÇÔ∏è RESEARCHER AGENT WORKING ---")
    task = state['task']
    
    # Step 1: Generate search queries using Gemini
    prompt_queries = f"You are a Market Researcher. Generate 3 specific search queries to find data about: {task}. Return only the queries separated by newlines."
    response_queries = llm.invoke(prompt_queries)
    queries = response_queries.content.split('\n')
    
    # Step 2: Execute search using the Tool
    aggregated_data = []
    for q in queries:
        if q.strip():
            print(f"   Searching for: {q.strip()}...")
            result = web_search.invoke(q.strip())
            aggregated_data.append(f"Query: {q}\nResult: {result}\n")
    
    return {
        "search_queries": queries,
        "research_data": "\n".join(aggregated_data)
    }

def analyst_node(state: AgentState):
    """
    Agent 2: Analyze the raw data to find trends, SWOT, and key insights.
    """
    print("--- üß† ANALYST AGENT WORKING ---")
    data = state['research_data']
    task = state['task']
    
    prompt_analysis = f"""
    You are a Senior Strategy Analyst. 
    Review the following research data regarding: {task}.
    
    DATA:
    {data}
    
    Identify:
    1. Key market trends.
    2. Competitor strengths and weaknesses.
    3. Any pricing signals.
    
    Provide a detailed logical analysis.
    """
    
    response = llm.invoke(prompt_analysis)
    return {"analysis": response.content}

def writer_node(state: AgentState):
    """
    Agent 3: Format the analysis into a C-Suite executive report.
    """
    print("--- ‚úçÔ∏è WRITER AGENT WORKING ---")
    analysis = state['analysis']
    
    prompt_writing = f"""
    You are an Executive Report Writer. 
    Take the following analysis and format it into a professional Markdown report.
    
    Include:
    -  EXECUTIVE SUMMARY
    - KEY FINDINGS
    - SWOT ANALYSIS TABLE
    - STRATEGIC RECOMMENDATION
    
    ANALYSIS CONTENT:
    {analysis}
    """
    
    response = llm.invoke(prompt_writing)
    return {"final_report": response.content}

# --- 4. BUILD THE GRAPH ---

workflow = StateGraph(AgentState)

# Add Nodes
workflow.add_node("researcher", researcher_node)
workflow.add_node("analyst", analyst_node)
workflow.add_node("writer", writer_node)

# Add Edges (Sequential Flow)
workflow.set_entry_point("researcher")
workflow.add_edge("researcher", "analyst")
workflow.add_edge("analyst", "writer")
workflow.add_edge("writer", END)

# Compile
app = workflow.compile()
